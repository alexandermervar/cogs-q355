{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 - Tensorflow\n",
    "## Alexander Mervar - 3.9.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.0\n",
      "Keras Version: 2.4.0\n",
      "\n",
      "Python 3.8.12 | packaged by conda-forge | (default, Jan 30 2022, 23:33:09) \n",
      "[Clang 11.1.0 ]\n",
      "Pandas 1.4.1\n",
      "Scikit-Learn 1.0.2\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "**Using the tensorflow Keras API, build and train a deep network that classifies the MNIST-fashion dataset as accurately as possible. Submit your code to Canvas (10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3665 - accuracy: 0.8918\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0986 - accuracy: 0.9699\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0678 - accuracy: 0.9788\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0526 - accuracy: 0.9832\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0413 - accuracy: 0.9862\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0666656568646431, 0.9789999723434448]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "**Try to optimize your code to achieve a higher percentage accuracy by manipulating parameters such as dropout, stride, and the numbers of units in each layer. Describe in a short essay what network structures and design choices lead to better performance?  Why do you think that is? (10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 37s 19ms/step - loss: 0.3922 - accuracy: 0.8788\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 39s 19ms/step - loss: 0.1059 - accuracy: 0.9683\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 40s 20ms/step - loss: 0.0740 - accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 43s 22ms/step - loss: 0.0596 - accuracy: 0.9802\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 45s 23ms/step - loss: 0.0523 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 42s 21ms/step - loss: 0.0496 - accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 42s 21ms/step - loss: 0.0407 - accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 44s 22ms/step - loss: 0.0366 - accuracy: 0.9886\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 44s 22ms/step - loss: 0.0313 - accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 43s 21ms/step - loss: 0.0308 - accuracy: 0.9898\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04672878608107567, 0.9866999983787537]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Convulutional 2D layer to extract the most relevant features\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(2,2),strides=(1, 1), padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    # Max pooling layer to reduce the size of the feature maps and account for shifted visual features between images\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    # Add noise to the feature maps to prevent overfitting\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    # Flatten the feature maps to a 1D vector\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Add a fully connected layer with 256 output nodes\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    # Add noise to the feature maps to prevent overfitting\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # Add a fully connected layer with 10 output nodes (the final guess)\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Reshape for the CNN which expects a 28x28 image\n",
    "x_train = x_train.reshape(-1,28, 28,1)\n",
    "x_test = x_test.reshape(-1,28, 28, 1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=30)\n",
    "\n",
    "model.evaluate(x_test, y_test, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Essay\n",
    "The first model is very similar to the neural networks that we built for previous assignments. That model has one hidden layer of 512 output nodes that connects to 10 nodes signaling what the models guess is. For that particularly simple model. It is actually pretty efficient. But, by implementing a convolusion layer and a max pooling layer, the inputted image if filtered to be solely its most important features, which can then be analyzed to make the model's guess. The convolutionary layer acts as a visual filter to extract the most important features. It does not change the image shape instead, it alters each pixels value to make it easier for the neural network to see important features. Following that, the max pooling layer takes the feature map, which is created from the convolutional layer and reduces it's size for quicker processing. This will also help with overfitting. Following that, we flatten the image to an array of one dimension and process it through a similar network to the one created in the first exercise. I make sure to keep dropout involved in the process so overfitting is handled appropriately. As you can see, the efficiency is much greater in the second model with these addendums. All of these design choices make it faster and easier for the network to pick up what is most important for processing rather than take the raw image and training based on that. By applying these filters we extract the most relevant information. By max pooling, we decrease the amount of information provided and know that we can work with only the important features. After that, a standard neural network is created."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38a658a53124394ac0ef1c7369b293e13d105503c6978e65670dcc7433b1ca8c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
