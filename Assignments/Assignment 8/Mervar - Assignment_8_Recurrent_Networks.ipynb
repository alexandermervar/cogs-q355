{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 8 Recurrent Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lThy2RtN1wAJ",
        "outputId": "37ef028d-ea7f-4bdc-98e6-350f615444f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Colab Notebooks/lstm_lyrics/'\n",
            "/content/gdrive/My Drive/Colab Notebooks/lstm_lyrics\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My\\ Drive/Colab\\ Notebooks/lstm_lyrics/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1\n",
        "**Train the network**  \n",
        "Note: The network does crash. I will be using my best trained network."
      ],
      "metadata": {
        "id": "hP93BJNoGj3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python lstm_train.py corpora/pf.txt examples.txt vocabulary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgXH6lvXGiyX",
        "outputId": "794a5e8e-ef90-41d8-b6fc-bb643eba404c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length in characters: 189632\n",
            "Corpus length in words: 35328\n",
            "Unique words before ignoring: 5599\n",
            "Ignoring words with frequency < 10\n",
            "Unique words after ignoring: 368\n",
            "Ignored sequences: 34491\n",
            "Remaining sequences: 827\n",
            "Shuffling sentences\n",
            "Size of training set = 810\n",
            "Size of test set = 17\n",
            "Build model...\n",
            "2022-04-08 16:57:26.363142: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "lstm_train.py:210: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)\n",
            "lstm_train.py:56: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n",
            "lstm_train.py:57: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((batch_size, len(words)), dtype=np.bool)\n",
            "Epoch 1/100\n",
            "26/26 [==============================] - ETA: 0s - loss: 5.5993 - accuracy: 0.19232022-04-08 16:57:36.370926: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f618029a790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f61801df190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "26/26 [==============================] - 30s 1s/step - loss: 5.5993 - accuracy: 0.1923 - val_loss: 4.5855 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "lstm_train.py:56: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n",
            "lstm_train.py:57: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((batch_size, len(words)), dtype=np.bool)\n",
            "26/26 [==============================] - 12s 483ms/step - loss: 4.5239 - accuracy: 0.2272 - val_loss: 4.4840 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 12s 487ms/step - loss: 4.3312 - accuracy: 0.2224 - val_loss: 4.7020 - val_accuracy: 0.2188\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 13s 516ms/step - loss: 4.2607 - accuracy: 0.2260 - val_loss: 4.6012 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 12s 484ms/step - loss: 4.2091 - accuracy: 0.2212 - val_loss: 4.8675 - val_accuracy: 0.2188\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 12s 484ms/step - loss: 4.0932 - accuracy: 0.2260 - val_loss: 4.8120 - val_accuracy: 0.2500\n",
            "2022-04-08 16:58:58.648935: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
            "\t [[{{node PyFunc}}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the generate.py script to generate 10 different samples of text from the trained network."
      ],
      "metadata": {
        "id": "88NU5setnpSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated Sample 01:  \n",
        "Seed: \"the\"  \n",
        "Diversity: 1  \n",
        "Sequence Length: 1  \n",
        "Quantity: 10  \n",
        "  \n",
        "Generated Sample 02:  \n",
        "Seed: \"gun\"  \n",
        "Diversity: 2  \n",
        "Sequence Length: 5  \n",
        "Quantity: 10 \n",
        "  \n",
        "Generated Sample 03:  \n",
        "Seed: \"Butch\"  \n",
        "Diversity: 3  \n",
        "Sequence Length: 10  \n",
        "Quantity: 10  \n",
        "  \n",
        "Generated Sample 04:  \n",
        "Seed: \"God\"  \n",
        "Diversity: 4  \n",
        "Sequence Length: 15  \n",
        "Quantity: 10 \n",
        "  \n",
        "Generated Sample 05:  \n",
        "Seed: \"coffee\"  \n",
        "Diversity: 5  \n",
        "Sequence Length: 20  \n",
        "Quantity: 10  \n",
        "  \n",
        "Generated Sample 06:  \n",
        "Seed: \"sword\"  \n",
        "Diversity: 6  \n",
        "Sequence Length: 30  \n",
        "Quantity: 10 \n",
        "  \n",
        "Generated Sample 07:  \n",
        "Seed: \"running\"  \n",
        "Diversity: 7  \n",
        "Sequence Length: 40  \n",
        "Quantity: 10  \n",
        "  \n",
        "Generated Sample 08:  \n",
        "Seed: \"dance\"  \n",
        "Diversity: 8  \n",
        "Sequence Length: 10  \n",
        "Quantity: 10 \n",
        "  \n",
        "Generated Sample 09:  \n",
        "Seed: \"milkshake\"  \n",
        "Diversity: 9  \n",
        "Sequence Length: 10  \n",
        "Quantity: 10  \n",
        "  \n",
        "Generated Sample 10:  \n",
        "Seed: \"suit\"  \n",
        "Diversity: 10  \n",
        "Sequence Length: 10  \n",
        "Quantity: 10 \n",
        "  \n"
      ],
      "metadata": {
        "id": "4JworoZcFLm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This was the latest checkpoints file generated (I think something weird was going on)\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"the\" -q 10 -d 1 -l 1\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"gun\" -q 10 -d 2 -l 5\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"goddamn\" -q 10 -d 3 -l 10\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"hands\" -q 10 -d 4 -l 15\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"coffee\" -q 10 -d 5 -l 20\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"lance\" -q 10 -d 6 -l 30\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"mean\" -q 10 -d 7 -l 40\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"taking\" -q 10 -d 8\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"which\" -q 10 -d 9\n",
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch002-words368-sequence10-minfreq10-loss4.4939-acc-val_loss4.6151-val_acc0.1250 -s \"into\" -q 10 -d 10"
      ],
      "metadata": {
        "id": "gIS-W20r9uFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505a42fb-273d-4e61-a719-dcd90923951a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-08 17:53:46.034254: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "the ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:1.0\n",
            "----- Generating with seed:\n",
            "\"the\n",
            "the\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 1, 368)\n",
            "\n",
            "2022-04-08 17:53:57.472275: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "gun ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:2.0\n",
            "----- Generating with seed:\n",
            "\"gun gun gun gun gun\n",
            "gun gun gun gun gun\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 5, 368)\n",
            "\n",
            "2022-04-08 17:54:08.890288: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "goddamn ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:3.0\n",
            "----- Generating with seed:\n",
            "\"goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn\n",
            "goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn goddamn\n",
            " don't here, in 'em under like this the where back\n",
            "\n",
            "2022-04-08 17:54:22.093505: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "hands ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:4.0\n",
            "----- Generating with seed:\n",
            "\"hands hands hands hands hands hands hands hands hands hands hands hands hands hands hands\n",
            "hands hands hands hands hands hands hands hands hands hands hands hands hands hands hands\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 15, 368)\n",
            "\n",
            "2022-04-08 17:54:33.778798: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "coffee ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:5.0\n",
            "----- Generating with seed:\n",
            "\"coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee\n",
            "coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee coffee\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 20, 368)\n",
            "\n",
            "2022-04-08 17:54:45.420051: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "lance ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:6.0\n",
            "----- Generating with seed:\n",
            "\"lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance\n",
            "lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance lance\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 30, 368)\n",
            "\n",
            "2022-04-08 17:54:57.078678: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "mean ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:7.0\n",
            "----- Generating with seed:\n",
            "\"mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean\n",
            "mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean mean\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 40, 368)\n",
            "\n",
            "2022-04-08 17:55:08.796109: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "taking ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:8.0\n",
            "----- Generating with seed:\n",
            "\"taking taking taking taking taking taking taking taking taking taking\n",
            "taking taking taking taking taking taking taking taking taking taking\n",
            " man, only starts night coffee dave stand me, it, little\n",
            "\n",
            "2022-04-08 17:55:22.331108: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "which ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:9.0\n",
            "----- Generating with seed:\n",
            "\"which which which which which which which which which which\n",
            "which which which which which which which which which which\n",
            " to like before take should shit were door. have fuck\n",
            "\n",
            "2022-04-08 17:55:35.723609: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 256)              508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 603,504\n",
            "Trainable params: 603,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "into ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:10.0\n",
            "----- Generating with seed:\n",
            "\"into into into into into into into into into into\n",
            "into into into into into into into into into into\n",
            " marcellus' here, nods there's needle need takes say mia too\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2**  \n",
        "As sequence length goes above 10, the generation fails as the input parameter does not expect > 10 inputs."
      ],
      "metadata": {
        "id": "jx3nHP5eTT-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3**  \n",
        "When diversity increases, I assume that the variety of words selected as the next word increases. It's kind of hard to tell with the current quality of the generated text to certify that this is the case. The diversity is the \"temperature\" of the sample function.  \n",
        "**2.4**  \n",
        "The model is a Biderectional layer of shape 10->128, a possible dropout layer, a dense layer, and a softmax activation layer. The bidirectional layer is where the recursion takes place. Dropout fights overfitting. The dense and softmax layer is where a more standard neural network is created with a softmax activation function in order to create learning. The model is optimized with adam and uses a crossentropy loss function."
      ],
      "metadata": {
        "id": "nNVFcEU2TnhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a Second LSTM Layer"
      ],
      "metadata": {
        "id": "Q2peHE2LboLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python mervar_lstm_train.py corpora/pf.txt examples.txt vocabulary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chmcZ4YnZPHU",
        "outputId": "1039c5db-87fc-4726-809a-8568e4a5b051"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length in characters: 189632\n",
            "Corpus length in words: 35328\n",
            "Unique words before ignoring: 5599\n",
            "Ignoring words with frequency < 10\n",
            "Unique words after ignoring: 368\n",
            "Ignored sequences: 34491\n",
            "Remaining sequences: 827\n",
            "Shuffling sentences\n",
            "Size of training set = 810\n",
            "Size of test set = 17\n",
            "Build model...\n",
            "2022-04-09 04:09:27.012963: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "mervar_lstm_train.py:211: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)\n",
            "mervar_lstm_train.py:56: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n",
            "mervar_lstm_train.py:57: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((batch_size, len(words)), dtype=np.bool)\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 5.3217 - accuracy: 0.21632022-04-09 04:09:46.223529: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9c4017f190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9c40129090> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9bd4745c90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9bd4714a10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "26/26 [==============================] - 50s 2s/step - loss: 5.2949 - accuracy: 0.2175 - val_loss: 5.5083 - val_accuracy: 0.0938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py -v vocabulary.txt -n checkpoints/LSTM_LYRICS-epoch001-words368-sequence10-minfreq10-loss5.2949-acc-val_loss5.5083-val_acc0.0938 -s \"the\" -q 10 -d 1 -l 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxKragPgTmE",
        "outputId": "3f128bd2-866a-4ff4-b536-5d2fe2dcbf66"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-09 04:11:50.832848: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "Summary of the Network: \n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 10, 256)          508928    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 368)               94576     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 368)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 997,744\n",
            "Trainable params: 997,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Validating that all the words in the seed are part of the vocabulary: \n",
            "the ✓ in vocabulary\n",
            "\n",
            "Seed is correct.\n",
            "\n",
            "----- Generating text\n",
            "----- Diversity:1.0\n",
            "----- Generating with seed:\n",
            "\"the\n",
            "the\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 133, in <module>\n",
            "    model, indices_word, word_indices, seed, sequence_length, diversity, quantity\n",
            "  File \"generate.py\", line 67, in generate_text\n",
            "    preds = model.predict(x_pred, verbose=0)[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1147, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 368), found shape=(None, 1, 368)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Off the bat, the accuracy was higher with this added layer. But, due to the lack of significant training, it was hard to notice a difference from the generate text. (Note: The generate function above failed so I took the example (see below from the examples.txt file with diversity of 0.7.)"
      ],
      "metadata": {
        "id": "Zi3KBxPBgGd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "int. jimmie's bathroom – day \n",
        " \n",
        " jules\"\n",
        "\n",
        " \n",
        " int. jimmie's bathroom – day \n",
        " \n",
        " jules \n",
        " while on butch man just shit \n",
        " i on the door. as \n",
        " the the \n",
        " jimmie's \n",
        " good \n",
        " your the the time \n",
        " i \n",
        " the \n",
        " the night to it? the \n",
        " \n",
        " on an \n",
        " the find take \n",
        " \n",
        " the of \n",
        " the \n"
      ],
      "metadata": {
        "id": "SgYpNa8SiJ-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The added layer gave an additional 20s of compiling, which is very significant. To be honest, looking at the different generated text, I see no benefit. But, like discussed before, I see this as a lack of training, which is unfortuante do to the nature of the code being broken (or just undiagnosable with my current level of knowledge)."
      ],
      "metadata": {
        "id": "lf84j-eviOMg"
      }
    }
  ]
}